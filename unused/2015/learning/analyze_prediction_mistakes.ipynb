{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions_rootdir = '/home/yuncong/csd395/CSHL_patch_predictions_svm_Sat16ClassFinetuned'\n",
    "# predictions_rootdir = '/home/yuncong/csd395/CSHL_patch_predictions_svm_Sat16ClassFinetuned_v2/'\n",
    "predictions_rootdir = create_if_not_exists('/home/yuncong/csd395/CSHL_patch_predictions_svm_Sat16ClassFinetuned_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "colors = np.random.randint(0, 255, (len(labels_index), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD589'\n",
    "# stack = 'MD594'\n",
    "first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "first_detection_sec, last_detection_sec = detect_bbox_range_lookup[stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "n_labels = len(labels_surroundIncluded_index)\n",
    "M = np.zeros((n_labels, n_labels), np.int)\n",
    "M_soft = np.zeros((n_labels, n_labels))\n",
    "\n",
    "mistakes_to_investigate = defaultdict(list)\n",
    "\n",
    "for sec in range(first_detection_sec, last_detection_sec+1):\n",
    "    \n",
    "    try:\n",
    "        true_labels = np.load('/home/yuncong/csd395/CSHL_patch_features_Sat16ClassFinetuned/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_labels.npy' % \\\n",
    "                         {'stack':stack, 'sec': sec})\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    print sec\n",
    "    \n",
    "    n = len(true_labels)\n",
    "    \n",
    "    scores = np.zeros((n, len(labels_surroundIncluded_index)))\n",
    "    for l in labels_surroundIncluded_list:\n",
    "        if not l.endswith('surround'):\n",
    "            scores[:, labels_surroundIncluded_index[l]] = np.load(predictions_rootdir + '/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_%(label)s_sparseScores.npy' % \\\n",
    "                         {'stack':stack, 'sec': sec, 'label': l})\n",
    "        else:\n",
    "            scores[:, labels_surroundIncluded_index[l]] = 1 - scores[:, labels_surroundIncluded_index[labels_from_surround[l]]]\n",
    "        \n",
    "#     hard_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "#     for hp, tl in zip(hard_predictions, true_labels):\n",
    "#         if tl == -1: continue\n",
    "#         M[tl, hp] += 1\n",
    "        \n",
    "    for i in range(n):\n",
    "        probs = scores[i]\n",
    "        tl = true_labels[i]\n",
    "        if tl == -1: \n",
    "            continue\n",
    "        \n",
    "        true_name = labels_surroundIncluded_list[tl]\n",
    "        correct_prob = probs[labels_surroundIncluded_index[true_name]]\n",
    "        if correct_prob < 1e-1:\n",
    "#             print i, true_name, correct_prob\n",
    "            \n",
    "            mistakes_to_investigate[sec].append((i, true_name, probs))\n",
    "            \n",
    "mistakes_to_investigate.default_factory = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_labels = np.load('/home/yuncong/csd395/CSHL_patch_features_Sat16ClassFinetuned/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_labels.npy' % \\\n",
    "                         {'stack':stack, 'sec': 160})\n",
    "mapping_indices_to_label = dict(zip(indices_allROIs_allSections[160]['roi1'], \n",
    "             [labels_surroundIncluded_list[tl] if tl != -1 else None for tl in true_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sp5_surround'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_indices_to_label[41155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11256,  9128])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_locations[41155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load sample locations\n",
    "\n",
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "patch_size, stride, w, h = grid_parameters.tolist()\n",
    "half_size = patch_size/2\n",
    "ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                 indexing='xy')\n",
    "sample_locations = np.c_[xs.flat, ys.flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mark_mistakes(stack, sec, mistakes_to_investigate, sample_locations, half_size):\n",
    "    \n",
    "    indices = [indices_allROIs_allSections[sec]['roi1'][m[0]] for m in mistakes_to_investigate[sec]]\n",
    "\n",
    "    titles = ['%d %s %.3f' % (indices_allROIs_allSections[sec]['roi1'][m[0]], m[1], m[2][labels_surroundIncluded_index[m[1]]]) for m in mistakes_to_investigate[sec]]\n",
    "    \n",
    "    patches = []\n",
    "    \n",
    "    dm = DataManager(stack=stack)\n",
    "    \n",
    "    img_fn = dm._get_image_filepath(stack=stack, section=sec, version='rgb-jpg')\n",
    "    img = imread(img_fn)\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    for ind, title in zip(indices, titles):\n",
    "        xc, yc = sample_locations[ind]\n",
    "    \n",
    "        patch_ymin = max(0, yc-half_size)\n",
    "        patch_ymax = min(h, yc+half_size)\n",
    "        patch_xmin = max(0, xc-half_size)\n",
    "        patch_xmax = min(w, xc+half_size)\n",
    "    \n",
    "        cv2.rectangle(img, \n",
    "                      (patch_xmin, patch_ymin),\n",
    "                      (patch_xmax, patch_ymax),\n",
    "                      (255, 0, 0), 5)\n",
    "        \n",
    "        cv2.putText(img, title, (patch_xmin, patch_ymin-10), cv2.FONT_HERSHEY_DUPLEX, 2, ((255,0,0)), 1)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
      ],
      "text/plain": [
       "/oasis/projects/nsf/csd395/yuncong/Brain/learning/tmp.jpg"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistake_img = mark_mistakes(stack, 160, mistakes_to_investigate, sample_locations, half_size)\n",
    "display_image(mistake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patches_from_indices(stack, sec, indices, sample_locations, half_size, return_context=False, context_size=500):\n",
    "    \n",
    "    patches = []\n",
    "    context_images = []\n",
    "    \n",
    "    dm = DataManager(stack=stack)\n",
    "    \n",
    "    img_fn = dm._get_image_filepath(stack=stack, section=sec, version='rgb-jpg')\n",
    "    img = imread(img_fn)\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    for i in indices:\n",
    "        xc, yc = sample_locations[i]\n",
    "    \n",
    "        patch_ymin = max(0, yc-half_size)\n",
    "        patch_ymax = min(h, yc+half_size)\n",
    "        patch_xmin = max(0, xc-half_size)\n",
    "        patch_xmax = min(w, xc+half_size)\n",
    "    \n",
    "#         print patch_xmin, patch_xmax, patch_ymin, patch_ymax\n",
    "    \n",
    "        patch = img[patch_ymin:patch_ymax+1, patch_xmin:patch_xmax+1]\n",
    "        patches.append(patch)\n",
    "        \n",
    "        if return_context:\n",
    "            context_ymin = max(0, yc-context_size)\n",
    "            context_ymax = min(h, yc+context_size)\n",
    "            context_xmin = max(0, xc-context_size)\n",
    "            context_xmax = min(w, xc+context_size)\n",
    "            \n",
    "#             print context_xmin, context_xmax, context_ymin, context_ymax\n",
    "        \n",
    "            context_image = img[context_ymin:context_ymax+1, context_xmin:context_xmax+1].copy()\n",
    "            cv2.rectangle(context_image, \n",
    "                          (patch_xmin - context_xmin, patch_ymin - context_ymin),\n",
    "                          (patch_xmax - context_xmin, patch_ymax - context_ymin),\n",
    "                        (255, 0, 0), 5)      \n",
    "        \n",
    "#             rs, cs = polygon_perimeter([patch_ymin - context_ymin, patch_ymin - context_ymin, \n",
    "#                                         patch_ymax - context_ymin, patch_ymax - context_ymin], \n",
    "#                                        [patch_xmin - context_xmin, patch_xmax - context_xmin, \n",
    "#                                         patch_xmax - context_xmin, patch_xmin - context_xmin],\n",
    "#                                       shape=context_image.shape)\n",
    "#             context_image[rs, cs] = (255,0,0)\n",
    "            \n",
    "            context_images.append(context_image)\n",
    "            \n",
    "    if return_context:\n",
    "        return patches, context_images\n",
    "    else:\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sec = first_detection_sec\n",
    "indices_to_investigate = [indices_allROIs_allSections[sec]['roi1'][m[0]] for m in mistakes_to_investigate[sec]]\n",
    "patches, context_images = patches_from_indices(stack, first_detection_sec, indices_to_investigate, sample_locations, half_size,\n",
    "                                              return_context=True, context_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = ['%s %.3f' % (m[1], m[2][labels_surroundIncluded_index[m[1]]]) for m in mistakes_to_investigate[sec]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10));\n",
    "plt.imshow(context_images[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_images_in_grids(patches, 5, titles=titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
