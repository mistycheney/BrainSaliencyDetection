{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "model_dir = '/home/yuncong/mxnet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'Sat16ClassFinetuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean_img = mx.nd.load(os.path.join(model_dir, 'mean_224.nd'))['mean_img'].asnumpy()\n",
    "mean_img = np.load(os.path.join(model_dir, model_name, 'saturation_mean_224.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_iteration = 10\n",
    "\n",
    "model0 = mx.model.FeedForward.load(os.path.join(model_dir, model_name, model_name), model_iteration, ctx=mx.gpu())\n",
    "\n",
    "flatten_output = model0.symbol.get_internals()['flatten_output']\n",
    "\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=flatten_output, num_epoch=model_iteration,\n",
    "                            arg_params=model0.arg_params, aux_params=model0.aux_params,\n",
    "                            allow_extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_name = 'Inception'\n",
    "# model_iteration = 9\n",
    "# model0 = mx.model.FeedForward.load(os.path.join(model_dir, 'inception-21k', model_name), model_iteration, ctx=mx.gpu())\n",
    "# flatten_output = model0.symbol.get_internals()['flatten_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = mx.viz.plot_network(flatten_output, shape={\"data\":(1, 1, 224, 224)}, node_attrs={\"shape\":'rect',\"fixedsize\":'false'})\n",
    "# a.render(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patch_features_rootdir = create_if_not_exists('/media/yuncong/BstemAtlasData/CSHL_patch_features_%(model_name)s_v2' % {'model_name': model_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_size = 224\n",
    "half_size = patch_size/2\n",
    "stride = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD603\n",
      "MD603-N11-2016.03.02-12.51.47_MD603_1_0031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "locate patches: 0.03 seconds\n",
      "load saturation image: 2.91 seconds\n",
      "extract, reshape, normalize: 17.10 seconds\n",
      "predict: 42.14 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23512 patches in ROI\n",
      "23512 roi samples\n",
      "MD603-IHC11-2015.12.03-14.10.59_MD603_3_0031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "save: 1.72 seconds\n",
      "locate patches: 0.03 seconds\n",
      "load saturation image: 2.17 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_stacks:\n",
    "\n",
    "for stack in ['MD603']:\n",
    "\n",
    "    print stack\n",
    "\n",
    "    filename_to_section, section_to_filename = DataManager.load_sorted_filenames(stack)\n",
    "    anchor_fn = DataManager.load_anchor_filename(stack)\n",
    "\n",
    "    image_width, image_height = DataManager.get_image_dimension(stack)\n",
    "    grid_spec = (patch_size, stride, image_width, image_height)\n",
    "\n",
    "    sample_locations = grid_parameters_to_sample_locations(grid_spec=grid_spec)\n",
    "\n",
    "    first_detect_sec, last_detect_sec = DataManager.load_cropbox(stack)[4:]\n",
    "\n",
    "    bar = show_progress_bar(first_detect_sec, last_detect_sec)\n",
    "\n",
    "#     for sec in range(213, 214):\n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+1):\n",
    "\n",
    "        fn = section_to_filename[sec]\n",
    "        if fn in ['Placeholder', 'Rescan', 'Nonexisting']:\n",
    "            continue\n",
    "            \n",
    "        print fn\n",
    "            \n",
    "        output_dir = create_if_not_exists(os.path.join(patch_features_rootdir, stack, \n",
    "                                       '%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped' % \\\n",
    "                                                       dict(fn=fn, anchor_fn=anchor_fn)))\n",
    "        output_indices_fn = os.path.join(output_dir, \n",
    "                                         '%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped_patch_locations.txt' % \\\n",
    "                                         dict(fn=fn, anchor_fn=anchor_fn))\n",
    "        if os.path.exists(output_indices_fn):\n",
    "            continue\n",
    "    \n",
    "        bar.value = sec\n",
    "\n",
    "#         mask_tb = DataManager.load_thumbnail_mask(stack=stack, section=sec, cerebellum_removed=True)\n",
    "        mask_tb = DataManager.load_thumbnail_mask_v2(stack=stack, section=sec)\n",
    "\n",
    "        t = time.time()\n",
    "        indices_roi = locate_patches(grid_spec=grid_spec, mask_tb=mask_tb, bbox=(0,0, image_width, image_height))\n",
    "        sys.stderr.write('locate patches: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        n = len(indices_roi)\n",
    "        print n, 'roi samples'\n",
    "\n",
    "        sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "        ##################################\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        sat = imread(DataManager.get_image_filepath(stack=stack, section=sec, version='saturation'))\n",
    "\n",
    "        sys.stderr.write('load saturation image: %.2f seconds\\n' % (time.time() - t)) # ~ 2s\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "#         patches = np.array([sat[y-half_size:y+half_size, x-half_size:x+half_size].copy()\n",
    "#                             for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "\n",
    "        patches = np.array([sat[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                            for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "        \n",
    "        patches_mean_subtracted = patches - mean_img\n",
    "        \n",
    "        patches_mean_subtracted_input = patches_mean_subtracted[:, None, :, :] # n x 1 x 224 x 224\n",
    "        #         patches = np.rollaxis(patches2, 3, 1)\n",
    "\n",
    "        sys.stderr.write('extract, reshape, normalize: %.2f seconds\\n' % (time.time() - t)) # ~ 4s / 20k patches\n",
    "\n",
    "        batch_size = 256 # increasing to 500 does not save any time\n",
    "#         batch_size = 16 # increasing to 500 does not save any time\n",
    "\n",
    "        data_iter = mx.io.NDArrayIter(\n",
    "            patches_mean_subtracted_input, \n",
    "            np.zeros((n, ), np.int), # labels are not important since it is just feed-forward\n",
    "            batch_size = batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "        features = model.predict(data_iter)\n",
    "        \n",
    "        sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))\n",
    "        # The first time CUDA needs to load model, which is very slow ~350s, but later runs are faster ~90s\n",
    "        \n",
    "    # Had to modify [model]-symbol.json according to this https://github.com/dmlc/mxnet/issues/2718\n",
    "    \n",
    "    # Out of memory after about 20 sections - had to modify storage code according to https://github.com/dmlc/mxnet/issues/3055\n",
    "    #    - don't think increasing kPoolThreshold to over 4GB will be beneficial, \n",
    "    # since the computation time is similar to before limiting the pool, computation is most likely compute-bound.\n",
    "    # Issue solved by developers.\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        output_dir = create_if_not_exists(os.path.join(patch_features_rootdir, stack, \n",
    "                                   '%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped' % dict(fn=fn, anchor_fn=anchor_fn)))\n",
    "\n",
    "        output_indices_fn = os.path.join(output_dir, \n",
    "                                         '%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped_patch_locations.txt' % \\\n",
    "                                         dict(fn=fn, anchor_fn=anchor_fn))\n",
    "        np.savetxt(output_indices_fn, np.c_[indices_roi, sample_locations_roi], fmt='%d %d %d')\n",
    "        \n",
    "        output_features_fn = os.path.join(output_dir, '%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped_features.hdf' % \\\n",
    "                                         dict(fn=fn, anchor_fn=anchor_fn))\n",
    "        save_hdf(features.astype(np.float16), output_features_fn) # bloscpack produces files of similar size\n",
    "        \n",
    "        sys.stderr.write('save: %.2f seconds\\n' % (time.time() - t)) # ~.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create symbolic links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# patch_features_sorted_rootdir = '/home/yuncong/CSHL_patch_features_Sat16ClassFinetuned_v2_sorted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cmd = ('mkdir %(patch_features_sorted_rootdir)s;'\n",
    "#        'cd %(patch_features_sorted_rootdir)s &&'\n",
    "#         'rm -rf %(stack)s &&'\n",
    "#       'mkdir %(stack)s') % \\\n",
    "#         dict(stack=stack, patch_features_sorted_rootdir=patch_features_sorted_rootdir)\n",
    "# execute_command(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD585', 'MD589', 'MD594']:\n",
    "    \n",
    "#     execute_command('cd %(patch_features_sorted_rootdir)s && rm -rf %(stack)s && mkdir %(stack)s;' % \\\n",
    "#                dict(stack=stack, patch_features_sorted_rootdir=patch_features_sorted_rootdir))\n",
    "\n",
    "#     filename_to_section, section_to_filename = DataManager.load_sorted_filenames(stack)\n",
    "\n",
    "#     for sec, fn in section_to_filename.iteritems():\n",
    "\n",
    "#         if fn in ['Placeholder', 'Nonexisting', 'Rescan']:\n",
    "#             continue\n",
    "    \n",
    "#         cmd = ('cd %(patch_features_sorted_rootdir)s/%(stack)s && mkdir %(stack)s_%(sec)04d_lossless_aligned_cropped; '\n",
    "#     'ln -s %(patch_features_unsorted_rootdir_relpath)s/%(stack)s/%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped/%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped_features.hdf '\n",
    "#     '%(stack)s_%(sec)04d_lossless_aligned_cropped/%(stack)s_%(sec)04d_lossless_aligned_cropped_features.hdf && '\n",
    "#     'ln -s %(patch_features_unsorted_rootdir_relpath)s/%(stack)s/%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped/%(fn)s_lossless_alignedTo_%(anchor_fn)s_cropped_patch_locations.txt '\n",
    "#     '%(stack)s_%(sec)04d_lossless_aligned_cropped/%(stack)s_%(sec)04d_lossless_aligned_cropped_patch_locations.txt') % \\\n",
    "#                 dict(stack=stack, sec=sec, anchor_fn=anchor_fn, fn=fn,\n",
    "#                     patch_features_unsorted_rootdir_relpath='../../../CSHL_patch_features_Sat16ClassFinetuned_v2',\n",
    "#                     patch_features_sorted_rootdir=patch_features_sorted_rootdir)\n",
    "#         execute_command(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sync with Gordon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = 'cd /home/yuncong/CSHL_patch_predictions/%(stack)s; rsync -r . yuncong@oasis-dm.sdsc.edu:/home/yuncong/csd395/CSHL_patch_features/%(stack)s' % \\\n",
    "{'stack': stack}\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = 'cd /home/yuncong/CSHL_patch_features_Sat16ClassFinetuned/%(stack)s/; \\\n",
    "rsync -r . yuncong@oasis-dm.sdsc.edu:/home/yuncong/csd395/CSHL_patch_features_Sat16ClassFinetuned/%(stack)s' % \\\n",
    "{'stack': stack}\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD593', 'MD602', 'MD592', 'MD585', 'MD590', 'MD591', 'MD595', 'MD598']:\n",
    "# # for stack in ['MD589']:\n",
    "    \n",
    "#     if stack in ['MD589', 'MD594']:\n",
    "#         stack_has_annotation = True\n",
    "#     else:\n",
    "#         stack_has_annotation = False\n",
    "\n",
    "#     dm = DataManager(stack=stack, data_dir='/media/yuncong/BstemAtlasData/CSHL_data_processed')\n",
    "\n",
    "#     table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "#     indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "#     grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "    \n",
    "#     patch_size, stride, w, h = grid_parameters.tolist()\n",
    "#     half_size = patch_size/2\n",
    "#     ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "#                      indexing='xy')\n",
    "#     sample_locations = np.c_[xs.flat, ys.flat]\n",
    "    \n",
    "#     if stack_has_annotation:\n",
    "#         table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "#         indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "\n",
    "#     first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "    \n",
    "#     bar = show_progress_bar(first_detect_sec, last_detect_sec)\n",
    "    \n",
    "#     for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "# #     for sec in range(first_detect_sec, first_detect_sec+10):\n",
    "# #     for sec in range(first_detect_sec, first_detect_sec+1):\n",
    "        \n",
    "#         if sec not in indices_allROIs_allSections.columns:\n",
    "#             continue\n",
    "            \n",
    "#         bar.value = sec\n",
    "                \n",
    "#         indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "        \n",
    "#         n = len(indices_roi)\n",
    "#         print n, 'roi samples'\n",
    "        \n",
    "#         ######################\n",
    "#         t = time.time()\n",
    "        \n",
    "#         true_labels = -1 * np.ones((99999,), np.int)\n",
    "#         if stack_has_annotation:\n",
    "#             if sec in indices_allLandmarks_allSections:\n",
    "#                 for l in indices_allLandmarks_allSections[sec].dropna().keys() & labels_surroundIncluded:\n",
    "#                     true_labels[indices_allLandmarks_allSections[sec][l]] = labels_surroundIncluded_index[l]\n",
    "#         patch_labels = true_labels[indices_roi]\n",
    "        \n",
    "#         create_if_not_exists(test_features_rootdir + '/%(stack)s/%(sec)04d' % {'stack': stack, 'sec': sec})\n",
    "#         np.save(test_features_rootdir + '/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_labels.npy' % \\\n",
    "#                 {'stack': stack, 'sec': sec}, \n",
    "#                 patch_labels)\n",
    "        \n",
    "#         sys.stderr.write('get true labels: %.2f seconds\\n' % (time.time() - t)) # ~ 0s\n",
    "                \n",
    "#         ######################\n",
    "        \n",
    "#         sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "#         t = time.time()\n",
    "        \n",
    "#         sat = imread(sat_rootdir + '/%(stack)s_saturation/%(stack)s_%(sec)04d_sat.jpg' % {'stack': stack, 'sec': sec})\n",
    "            \n",
    "#         sys.stderr.write('load saturation image: %.2f seconds\\n' % (time.time() - t)) # ~ 2s\n",
    "    \n",
    "#         t = time.time()\n",
    "    \n",
    "#         patches = np.array([sat[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "#                             for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "#         patches = patches - mean_img\n",
    "#         patches = patches[:, None, :, :] # n x 1 x 224 x 224\n",
    "# #         patches = np.rollaxis(patches2, 3, 1)\n",
    "    \n",
    "#         sys.stderr.write('extract, reshape, normalize: %.2f seconds\\n' % (time.time() - t)) # ~ 6s\n",
    "        \n",
    "#         batch_size = 256 # increasing to 500 does not save any time\n",
    "\n",
    "#         data_iter = mx.io.NDArrayIter(\n",
    "#             patches, \n",
    "#             np.zeros((n, ), np.int), # labels are not important since it is just feed-forward\n",
    "#             batch_size = batch_size,\n",
    "#             shuffle=False\n",
    "#         )\n",
    "\n",
    "#         t = time.time()\n",
    "\n",
    "#         features = model.predict(data_iter)\n",
    "        \n",
    "#         sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t)) # ~40s\n",
    "        \n",
    "#         t = time.time()\n",
    "        \n",
    "#         save_hdf(features, test_features_rootdir + '/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_features.hdf' % \\\n",
    "#                  {'stack': stack, 'sec': sec})\n",
    "        \n",
    "#         sys.stderr.write('save: %.2f seconds\\n' % (time.time() - t)) # ~.5s\n",
    "        \n",
    "#         del sat, patches, sample_locations_roi, features\n",
    "                \n",
    "#     del sample_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
