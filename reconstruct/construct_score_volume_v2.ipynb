{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct score volume from score maps of each landmark\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Gordon\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from conversion import images_to_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample_scheme = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paired_structures = ['5N', '6N', '7N', '7n', 'Amb', 'LC', 'LRt', 'Pn', 'Tz', 'VLL', 'RMC', 'SNC', 'SNR', '3N', '4N',\n",
    "                    'Sp5I', 'Sp5O', 'Sp5C', 'PBG', '10N', 'VCA', 'VCP', 'DC']\n",
    "singular_structures = ['AP', '12N', 'RtTg', 'SC', 'IC']\n",
    "structures = paired_structures + singular_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downscale_factor = 32\n",
    "voxel_z_size = section_thickness/(xy_pixel_distance_lossless * downscale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_scoremap_worker(sec, stack, label, downscale_factor):\n",
    "    try:\n",
    "#         scoremap = DataManager.load_scoremap(stack=stack, section=sec, label=label, downscale_factor=downscale_factor)\n",
    "        scoremap = DataManager.load_scoremap(stack=stack, section=sec, label=label, \n",
    "                                             downscale_factor=downscale_factor, \n",
    "                                             train_sample_scheme=train_sample_scheme)\n",
    "        return (sec-1, scoremap)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "f = lambda sec: load_scoremap_worker(sec, stack, label, downscale_factor)\n",
    "    \n",
    "def load_scoremaps_parallel(sections, stack, label, downscale_factor):\n",
    "    pool = Pool(4)\n",
    "    index_scoremap_tuples = pool.map(lambda sec: load_scoremap_worker(sec, stack, label, downscale_factor), \n",
    "                                     sections)\n",
    "    return dict(filter(None, index_scoremap_tuples))\n",
    "\n",
    "def load_scoremaps_sequential(sections, stack, label, downscale_factor):\n",
    "    scoremaps = {}\n",
    "    for sec in sections:\n",
    "        t = time.time()\n",
    "        try:\n",
    "            scoremaps[sec-1] = DataManager.load_scoremap(stack=stack, section=sec, label=label, downscale_factor=downscale_factor)\n",
    "        except:\n",
    "            pass\n",
    "        print time.time() - t\n",
    "    return scoremaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load scoremaps: 77.73 seconds\n",
      "Create score volume: 80.55 seconds\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD591']:\n",
    "    \n",
    "    first_sec, last_sec = metadata_cache['section_limits'][stack]\n",
    "    \n",
    "#     for label in structures:\n",
    "    for label in ['7N']:\n",
    "#     for label in ['Amb']:\n",
    "\n",
    "        print label\n",
    "    \n",
    "        t = time.time()\n",
    "        scoremaps = load_scoremaps_parallel(stack=stack, sections=range(first_sec, last_sec+1), label=label, downscale_factor=downscale_factor)\n",
    "#         scoremaps = load_scoremaps_sequential(stack=stack, sections=range(first_sec, last_sec+1), label=label, downscale_factor=downscale_factor)\n",
    "#         scoremaps = load_scoremaps_parallel(stack=stack, sections=range(200, 300), label=label, downscale_factor=downscale_factor)\n",
    "#         scoremaps = load_scoremaps_sequential(stack=stack, sections=range(200, 220), label=label, downscale_factor=downscale_factor)\n",
    "        sys.stderr.write('Load scoremaps: %.2f seconds\\n' % (time.time() - t))\n",
    "        \n",
    "#         del scoremaps\n",
    "        \n",
    "        score_volume, score_volume_bbox = images_to_volume(images=scoremaps, voxel_size=(1, 1, voxel_z_size), first_sec=first_sec-1, last_sec=last_sec-1)\n",
    "        \n",
    "        output_dir = create_if_not_exists(os.path.join(VOLUME_ROOTDIR, stack, 'score_volumes'))\n",
    "#         score_volume_filepath = os.path.join(output_dir, '%(stack)s_down%(ds)d_scoreVolume_%(label)s.bp' % \\\n",
    "#                                             dict(stack=stack, ds=downscale_factor, label=label))\n",
    "\n",
    "        score_volume_filepath = DataManager.get_score_volume_filepath(stack=stack, downscale=downscale_factor, label=label, train_sample_scheme=train_sample_scheme)\n",
    "        bp.pack_ndarray_file(score_volume.astype(np.float16), score_volume_filepath)\n",
    "        \n",
    "        sys.stderr.write('Create score volume: %.2f seconds\\n' % (time.time() - t)) # 50 seconds - load scoremap 4 processes\n",
    "\n",
    "        score_volume_bbox_filepath = DataManager.get_score_volume_bbox_filepath(stack=stack, downscale=downscale_factor, label=label)\n",
    "        np.savetxt(score_volume_bbox_filepath, np.array(score_volume_bbox)[None])\n",
    "    \n",
    "        del score_volume, scoremaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_volume = DataManager.load_score_volume(stack='MD603', label='7N', downscale=32, train_sample_scheme=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(score_volume[:,:,100], cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# volume_roi = bp.unpack_ndarray_file(volume_dir + '/%(stack)s_scoreVolume_%(label)s.bp' % {'stack': stack, 'label': '5N'})\n",
    "# plt.imshow(volume_roi[..., 300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from skimage.transform import rescale, resize\n",
    "\n",
    "# def load_scoremap_tb(sec):\n",
    "#     ''' \n",
    "#     Get scoremap. \n",
    "#     Assume scoremap is stored as a 2D array for scores of the full frame at thumbnail scale.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     sec : int\n",
    "#         section number\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     2d array\n",
    "#         downsampled full-frame scoremap\n",
    "#     '''\n",
    "#     global stack\n",
    "        \n",
    "#     img_fn = contourMap_rootdir + '/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_denseScoremapThumbnail_outerContour.hdf' % \\\n",
    "#                 {'stack': stack, 'sec': sec}\n",
    "\n",
    "#     contour_prob_map = load_hdf(img_fn)\n",
    "    \n",
    "# #     # crop at upper border of ROI box\n",
    "# #     xmin, ymin, w, h = detect_bbox_lookup[stack]\n",
    "# #     contour_prob_map[:ymin] = 0\n",
    "\n",
    "#     scoremap = resize(contour_prob_map, (h_down, w_down))\n",
    "#     return scoremap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
